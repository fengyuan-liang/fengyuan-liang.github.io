# AB测试介绍

## **01、**AB测试原理简介

**1、什么是AB测试？**

​	 AB测试其实来源于假设检验，我们现在有两个随机均匀的样本组A、B，对其中一个组A做出某种改动，实验结束后分析两组用户行为数据，通过显著性检验，判断这个改动对于我们所关注的核心指标是否有显著的影响。

​     **记住一点：** `AB测试就是对照实验`

![image-20220529172329454](https://my-typroa-photos.oss-cn-guangzhou.aliyuncs.com/images/image-20220529172329454.png)

在这个实验中，我们的假设检验如下：

```java
 原假设H0：这项改动不会对核心指标有显著的影响
 备选假设H1：这项改动会对核心指标有显著影响
```

​		如果我们在做完实验之后，通过显著性检验发现P值足够小，我们则推翻原假设，证明这项改动会对我们所关注的核心指标产生显著影响，否则接受原假设，认为该改动未产生显著影响。如果用一句话来概括的话，`AB测试其实就是随机均匀样本组的对照实验`。这个就是AB测试的原理。

**2、AB测试的一般流程**

​	AB测试会涉及到产品、开发、数据部门，流程较长，环节较复杂，对于很多还没有真正工作，或者说没有切实接触过AB测试的同学来说，实施起来可能有一定的难度，但是一般来说主要有以下几个步骤：

1、一般在开始实验之前，我们首先需要和相关的产品或者项目经理确定这个实验所要验证的改动点是什么。

2、在确认改动点之后，数据分析师需要设计实验中所需要去观测的一些核心指标，比如点击率、转化率等。

3、确定完核心指标之后，下一步就是计算实验所需的最少样本流量，实验样本越大，我们的结果越可信，但是对我们用户的不良影响就越大。所以我们需要计算能够显著地证明我们的策略有效的最少样本量。

4、然后还要结合目前的日均活跃的用户量，计算实验持续的时间周期。

5、在计算完所需样本量之后，就要设计流量分割策略，根据实验需要对样本流量进行分流分层，保证样本的随机和均匀分布，避免出现`辛普森悖论`。

6、以上准备工作就绪，就需要和PM以及开发同学确认可以开始实验。一般在上线正式实验之前，会通过小流量去看一段时间的灰度实验。这个灰度实验的目的就是`为了验证我们这个改动并不会造成什么特别极端的影响`。

7、在灰度之后就会正式发版，等到实验周期结束，我们对实验的结果进行显著性检验。

以上就是AB测试中所采用的一套常规流程。

![image-20220529172649468](https://my-typroa-photos.oss-cn-guangzhou.aliyuncs.com/images/image-20220529172649468.png)

## **02、**明确改动点和观测指标

**1、明确改动点**

实验开始之前，首先要和产品或者项目经理明确实验的变量是什么？我们要保证AB测试的“单一因素原则”，即每一个实验的评估的因素都是单一因素，一次实验不能糅合多个影响因素，否则会导致实验效果难以区分是哪个因素的影响。

**2、明确观测指标**

观测指标可以分为两种类型：

1、**绝对值类指标。**我们平常`直接计算就能得到的单个指标`，不需要多个指标计算得到。一般都是统计该指标在一段时间内的均值或者汇总值，比如DAU，平均停留时长等。这类指标一般较少作为AB测试的观测指标。

2、**比率类指标**。与绝对值类指标相对应，我们`不能直接计算得到，而是通过多个指标计算得到`。比如某页面的点击率，我们需要先计算页面的点击数和展现数，两者相除才能得到该指标。类似的，还有一些转化率、复购率等等。AB测试观测的大部分指标都是比率类指标。

为什么这里要区分不同类型的观测指标，因为在接下来的样本量计算中，这两类指标的样本量计算有所差别。

## **03、**样本量、实验周期计算

**1、AB测试样本量计算**

​	A/B 测试样本量的选取基于大数定律和中心极限定理。在计算样本量之前，我们先大致了解一下大数定律和中心极限定理：

```java
\1. 大数定律：当试验条件不变时，随机试验重复多次以后，随机事件的频率近似等于随机事件的概率。
\2. 中心极限定理：对独立同分布且有相同期望和方差的n个随机变量，当样本量很大时，样本的均值近似服从标准正态分布N(0,1)。
```

**说人话就是：只要样本量足够大，样本就能够代表整体的表现。这个足够大到底是多大呢?**

每一个实验组所需的样本量计算公式如下：

![img](https://pic1.zhimg.com/80/v2-4420afb04aebca3a929562f4474fc790_720w.jpg)

在这个公式当中，

**σ代表的是样本数据的标准差，衡量的是整体样本数据的波动性，可以计算样本的标准差计算得到。**

**而δ代表的是预期实验组和对照组两组数据的差值，比如说期望点击率从20%提升到25%，那么δ就是5%。**

**而α和β，也就是我们在统计学当中所经常提到的，犯第一类错误的概率和第二类错误的概率。**

其中：

```java
1、α为犯第一类错误的概率，把没有犯第一类错误的概率1-α称为置信水平。一般情况下，α取值为0.05。
2、β为犯第二类错误的概率，把统计功效定义为1-β，一般情况下，β取值0.2，则统计功效的取值为0.8。
```

当观测的指标为绝对值类型/比率型指标时，样本的标准差的计算公式有所差异，

**当观测指标为绝对值类指标时：**

![img](https://pic1.zhimg.com/80/v2-bc9d3fdadf31bc52889eb71457f171f8_720w.jpg)

**当观测指标为比率类指标时：**

![img](https://pic2.zhimg.com/80/v2-b55a5b5df0013b40c1410df7ec90acb9_720w.jpg)

其中PA、PB分别为对照组和实验组的观测数据，**举个栗子，我们希望点击率从20%提升到25%，那么PA=20%，PB=25%，δ=5%。**



**如果上面的公式觉得不好理解，那我们就举个栗子计算一下！**

**栗子1-对于绝对值指标：**

```text
某商品详情页平均停留时长的标准差是20秒，优化了商品详情页后，预估至少有5秒的绝对提升，AB测试每个组需要的最少样本量：
σ=20，δ=5
每个组所需的最少样本量 = 820202/55=256
```

**栗子2-对于比率类指标：**

```java
某商品详情页点击率20%，优化了该功能后，预期点击率提升到25%，AB测试每个组需要的最少样本量：
对照组PA：20%，实验组PB：25%
每个组所需的最少样本量 = 8 * （20%（1-20%）+25%（1-25%））/ （25%- 20%）^2=1030
计算出单个实验组所需的样本量，若有多个实验组，乘以实验组的个数就可以得到最终的样本量。
```

**公式虽然明白怎么算了，但是我还是不想手算怎么办？我们有现成的工具可以直接使用！**

好用的在线计算工具：**Evans awesome AB Tools：(https://www.evanmiller.org/ab-testing/)**

它的界面是这样的，

![image-20220529174827859](https://my-typroa-photos.oss-cn-guangzhou.aliyuncs.com/images/image-20220529174827859.png)

其实工具都已经帮我们设计好了，关键就是我们需要理解在这个工具当中，他所提到的一些关键的指标对应的是我们刚才所说的哪个指标？

**第一个需要我们确定的是baseline conversion rate**，这个baseline conversion rate指的是我们在开始实验之前，对照组本身真实的表现情况，如果说我们在这个实验当中想要去观测的是点击率变化，那么baseline conversion rate就是原来的点击率是多少，**对应的就是前面提到的PA**。

**第二个需要我们确定的是minimum detectable effect**，这个指的就是你的改动预期带来的提升，举之前的例子，我们希望通过优化，点击率从20%提升到25%，那么这个绝对（absolute）提升是5%（25%-20%），如果选择相对（relative）提升，就是30%（26%-20%)/20%=30%，这个**对应的就是前面提到的δ**。

**除了这两个参数之外，还有就是significance level**，也就是我们所说的显著性水平，这个就**对应前面的第一类错误的概率，也就是α**，一般为5%。还有statistical power，也就是我们前面所说的统计功效，statistical power一般用1-β来表示，这里的话也就是80%，和之前保持一致。

**Evans AB Tools这个工具不仅可以计算AB测试的样本量，AB测试结果的显著性分析验证也可以使用，卡方检验、T检验、方差分析等，应有尽有，从样本量计算到结果验证，一个工具就搞定了！**我们后面的结果验证就是用这个工具进行的，这里就不再展开了。

![image-20220529174610578](https://my-typroa-photos.oss-cn-guangzhou.aliyuncs.com/images/image-20220529174610578.png)

## **04、**AB测试流量分割

**1、辛普森悖论**

为什么要进行合理的流量分割？

再举个栗子！

我们对APP上一个按钮进行了颜色调整，需要比较一下颜色调整前后用户点击率是否提高？经过一段时间的试验，我们得到了两组试验的数据，计算出了两组试验的点击率，如下：

![img](https://pic1.zhimg.com/80/v2-996e222070f2851edface025e1ca6270_720w.jpg)

数据中我们发现，单独看这一试验，无论是女性人群和男性人群，数据表现都是A组中较好，但是，总计却是B组效果较好，细分的结果和总计的结果相悖，这就是我们常说的**辛普森悖论**。

![image-20220529173058319](https://my-typroa-photos.oss-cn-guangzhou.aliyuncs.com/images/image-20220529173058319.png)

那么，问题出在哪里呢？我们发现这个AB测试的两个组的性别选取有问题，性别特征并没有均衡的分布在两个组中。很明显，A组里女性用户只有男性用户的1/3，而B组里女性用户是男性用户的3倍。

所以，这一组不成功的AB测试，主要是因为流量分割忽略了一个重要的“隐藏因素”，也就是性别比例。性别上的差异在A、B组中也成为了影响结果的一个变量，从而导致最终的结果相悖。`正确的试验实施方案里，除被测试的变量外，其他可能影响结果的变量的比例都应该保持一致，这就需要对流量进行均匀合理的分割。`

**2、分流分层原理**

流量的分割常用的有分流和分层。

**1）分流**

**用户分流是指按照地域、性别、年龄等把用户均匀地分为几个组，1个用户只能出现在1个组中。**但是实际情况中，往往会同时上线多个实验，拿广告来说，有针对样式形态的实验，有针对广告位置策略的实验，有针对预估模型的实验。如果只是按照这种分流模式来，在每组实验放量10%的情况下，整体的流量只能同时开展10个实验。这个实验的效率是非常低的。为了解决这个问题，提出了用户分层、流量复用的方法。

**2）分层**

**同一份流量可以分布在多个实验层，也就是说同一批用户可以出现在不同的实验层，**前提是各个实验层之间无业务关联，保证这一批用户都均匀地分布到所有的实验层里，达到用户“正交”的效果就可以。所谓的正交分层，其实可以理解为互不影响的流量分层，从而实验流量复用的效果。

**3）分流分层模型**

![img](https://pic4.zhimg.com/80/v2-2afcb35ffa9c179016f23ad913c7420f_720w.jpg)

对以上模型进行解释：

- 分流：组1、组2通过分流的方式分为2组流量，此时组1和组2是互斥的，即**组1+组2=100%试验流量**。
- 分层：流量流过组2中的B1层、B2层、B3层时，B1层、B2层、B3层的流量都是与组2的流量相等，相当于对组2的流量进行了复用，即**B1层=B2层=B3层=组2**
- 扩展：流量流过组2中的B1层时，又把B1层分为了B1-1，B1-2，B1-3，此时B1-1，B1-2，B1-3之间又是互斥的，即**B1-1层+B1-2层+B1-3层=B1层**。

根据以上规则我们可以不断地在此模型中增加组、层，并且可以互相嵌套。这要与实际的业务相匹配，拆分过多的结构可能会把简单的业务复杂化，拆分过少的结构又可能不满足实际业务。

## 05、AB测试使用场景

1、体验优化

用户体验永远是卖家最关心的事情之一，但随意改动已经完善的落地也是一件很冒险的事情，因此很多卖家会通过AB测试进行决策。常见的是在保证其他条件一致的情况下，针对某一单一的元素进行AB两个版本的设计，并进行测试和数据收集，最终选定数据结果更好的版本。

2、转化率优化

通常影响电商销售转化率的因素有产品标题、描述、图片、表单、定价等，通过测试这些相关因素的影响，不仅可以直接提高销售转化率，长期进行也能提高用户体验。

3、广告优化

广告优化可能是AB测试最常见的应用场景了，同时结果也是最直接的，营销人员可以通过AB测试的方法了解哪个版本的广告更受用户的青睐，哪些步骤怎么做才能更吸引用户。

## 06、AB测试工具

​	Apache附带的ab，它非常容易使用，ab可以直接在Web服务器本地发起测试请求。这至关重要，因为我们希望测试的服务器的处理时间，而不包含数据的网络传输时间以及用户PC本地的计算时间。

​	需要清楚的是，ab进行一切测试的本质都是基于HTTP，所以可以说它是对于Web服务器软件的黑盒性能测试，它获得的一切数据和计算结果，都可以通过HTTP来解释。

​	另有一些[压力测试](https://linuxeye.com/tag/压力测试/)软件，包括LoadRnner、Jmeter等，则是不同程度上包含了服务器处理之外的时间，比如LoadRunner运行在用户PC上，可以录制浏览器行为，这种测试的结果玩玩侧重于站点用户的角度，有另外一些层面的参考意义。

### 命令

```
ab.exe -n1000 -c200 "请求路径"        -n 请求次数  -c 并发数
```

### 命令参数

1. `-n    测试会话中所执行的请求个数,默认仅执行一个请求`

2. `-c    一次产生的请求个数,即同一时间发出多少个请求,默认为一次一个`

3. `-t    测试所进行的最大秒数,默认为无时间限制....其内部隐含值是[-n 50000],它可以使对服务器的测试限制在 `	      `一个固定的总时间以内`

4. `-p    包含了需要POST的数据的文件`

5. -T   POST数据所使用的Content-type头信息

6. -v   设置显示信息的详细程度

7. -w  以HTML表格的形式输出结果,默认是白色背景的两列宽度的一张表

8. -i    做HEAD请求而不是GET.

9. -x   设置<table>属性的字符串,此属性被填入<table 这里>

10. -y   设置<tr>属性的字符串

11. -z   设置<td>属性的字符串

12. -C   对请求附加一个Cookie行，其典型形式是name=value的参数对,此参数可以重复

13. -H   对请求附加额外的头信息,此参数的典型形式是一个有效的头信息行,其中包含了以冒号分隔的字段和值    		的对  (如"Accept-Encoding: zip/zop;8bit")

14. -A   HTTP验证,用冒号:分隔传递用户名及密码

15. -P   无论服务器是否需要(即是否发送了401认证需求代码),此字符串都会被发送

16. -X   对请求使用代理服务器

17. -V   显示版本号并退出

18. -k   启用HTTP KeepAlive功能,即在一个HTTP会话中执行多个请求,默认为不启用KeepAlive功能

19. -d   不显示"percentage served within XX [ms] table"的消息(为以前的版本提供支持)

20. -S   不显示中值和标准背离值,且均值和中值为标准背离值的1到2倍时,也不显示警告或出错信息, 默认会显示 		最小值/均值/最大值等(为以前的版本提供支持)  

21. -g   把所有测试结果写入一个'gnuplot'或者TSV(以Tab分隔的)文件   

22. -e    产生一个以逗号分隔的(CSV)文件,其中包含了处理每个相应百分比的请求所需要(从1%到100%)的相应	   百分比的(以微妙为单位)时间

23. -h   显示使用方法

24. -k   发送keep-alive指令到服务器端

### 输出信息

Server Software:                Apache/2.4.18                   服务器软件版本
Server Hostname:             127.0.0.1                          请求的URL
Server Port:                      80                                    请求的端口号

Document Path:                /                                      请求的服务器的路径
Document Length:            19590 bytes                        页面长度   单位是字节

Concurrency Level:            200                                   并发数
Time taken for tests:         124.509 seconds                  一共使用了124s      
Complete requests:           1000                                  请求的次数
Failed requests:                 9                                       失败的请求     
   (Connect: 0, Receive: 0, Length: 9, Exceptions: 0)
Total transferred:              19669661 bytes                    总共传输的字节数  http头信息
HTML transferred:             19472463 bytes                    实际页面传递的字节数
Requests per second:        8.03 [#/sec] (mean)                每秒多少个请求
Time per request:             24901.805 [ms] (mean)           平均每个用户等待多长时间
Time per request:            124.509 [ms] (mean, across all concurrent requests) 服务器平均用多长时间处理
Transfer rate:                  154.28 [Kbytes/sec] received     每秒获取多少数据

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    1   3.0      0      62
Processing:  4679 17276 7877.7  15587   64050
Waiting:     4675 17273 7877.1  15586   64050
Total:       4679 17277 7877.8  15588   64051

Percentage of the requests served within a certain time (ms)
  50%  15588    50%的用户的请求15588ms内返回
  66%  21097
  75%  24071
  80%  25294
  90%  27939
  95%  29550
  98%  32122
  99%  34885
 100%  64051 (longest request)

## 07、参考资料

AB测试的理解：https://zhuanlan.zhihu.com/p/432025060

AB测试理论解析：https://www.bilibili.com/video/BV1gV411E7Sc?spm_id_from=333.880.my_history.page.click